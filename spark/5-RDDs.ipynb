{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "098f2de1-0169-4952-b5dd-afa3f705c11e",
   "metadata": {},
   "source": [
    "## Session Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34968695-977e-48f2-8dac-96fc83439424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext()\n",
    "spark = pyspark.sql.SparkSession(sc, jsparkSession=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4176ab-d013-4d49-980e-a05bcb6d695a",
   "metadata": {},
   "source": [
    "## Load data into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9fd712a-002e-4a76-9fdc-a34ad8bb78e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = Path.cwd().parent / \"Files\" / \"bookcontents.csv\"\n",
    "book = str(path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a485d149-5d4f-4f82-83bb-fcfec408506e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----+\n",
      "|Chapter|                Name|Page|\n",
      "+-------+--------------------+----+\n",
      "|      1|        Introduction|  11|\n",
      "|      2|Basic Engineering...|  19|\n",
      "|      3|Advanced Engineer...|  28|\n",
      "|      4|     Hands On Course|  60|\n",
      "|      5|        Case Studies|  62|\n",
      "|      6|Best Practices Cl...|  73|\n",
      "|      7|130+ Data Sources...|  77|\n",
      "|      8|1001 Interview Qu...|  82|\n",
      "|      9|Recommended Books...|  87|\n",
      "+-------+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Chapters\n",
    "bookChaptersDF = spark.read.option(\"inferSchema\",\"true\").option(\"header\",\"true\").csv(book)\n",
    "bookChaptersDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f34c4ff-8ed9-4124-891e-987a67beb7c4",
   "metadata": {},
   "source": [
    "## Create RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04f717de-7af3-4695-bc57-bc71b12b0098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RDD from DataFrame\n",
    "bookRDD = bookChaptersDF.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa4fe3a7-d4c0-4732-a25a-51fdba016a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Chapter=1, Name='Introduction', Page=11)\n",
      "Row(Chapter=2, Name='Basic Engineering Skills', Page=19)\n",
      "Row(Chapter=3, Name='Advanced Engineering Skills', Page=28)\n",
      "Row(Chapter=4, Name='Hands On Course', Page=60)\n",
      "Row(Chapter=5, Name='Case Studies', Page=62)\n"
     ]
    }
   ],
   "source": [
    "# Inspect selection of RDD\n",
    "for row in bookRDD.take(5): \n",
    "        print(row) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ae20705-f123-4fd5-9fd8-41275a68e51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Chapter=1, Name='Introduction', Page=11)\n",
      "Row(Chapter=2, Name='Basic Engineering Skills', Page=19)\n",
      "Row(Chapter=3, Name='Advanced Engineering Skills', Page=28)\n",
      "Row(Chapter=4, Name='Hands On Course', Page=60)\n",
      "Row(Chapter=5, Name='Case Studies', Page=62)\n",
      "Row(Chapter=6, Name='Best Practices Cloud Platforms', Page=73)\n",
      "Row(Chapter=7, Name='130+ Data Sources Data Science', Page=77)\n",
      "Row(Chapter=8, Name='1001 Interview Questions', Page=82)\n",
      "Row(Chapter=9, Name='Recommended Books and Courses', Page=87)\n"
     ]
    }
   ],
   "source": [
    "# Inspect all RDD\n",
    "for row in bookRDD.collect(): \n",
    "        print(row) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc763fe-8fcb-43d0-8cba-5d9116df75ee",
   "metadata": {},
   "source": [
    "## Modify RDD to create compound column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd33e665-65c7-4c0f-b029-2159d2effcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create compound column\n",
    "splitRDD = bookRDD.map(lambda x: (x[0], (str(x[2]) + \"/\" + x[1]) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db2ae041-dd8b-4bbf-8fd3-6b849e371b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, '11/Introduction')\n",
      "(2, '19/Basic Engineering Skills')\n",
      "(3, '28/Advanced Engineering Skills')\n",
      "(4, '60/Hands On Course')\n",
      "(5, '62/Case Studies')\n",
      "(6, '73/Best Practices Cloud Platforms')\n",
      "(7, '77/130+ Data Sources Data Science')\n",
      "(8, '82/1001 Interview Questions')\n",
      "(9, '87/Recommended Books and Courses')\n"
     ]
    }
   ],
   "source": [
    "# Inspect new RDD\n",
    "for row in splitRDD.collect():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899e1498-f452-4e16-a003-e7cb8440a151",
   "metadata": {},
   "source": [
    "## Turn RDD back to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d0e0045-4437-497a-a7a6-1c69d23b6009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create schema for DataFrame\n",
    "from pyspark.sql.types import *\n",
    "compoundSchema = StructType([\n",
    "StructField(\"Chapter\",IntegerType()),\n",
    "StructField(\"Compound\",StringType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8c8c08d-468a-4c17-9299-42f8a84364e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "compoundDF = spark.createDataFrame(splitRDD,compoundSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "747b8d3a-4cb2-4465-87ea-71306a409b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|Chapter|            Compound|\n",
      "+-------+--------------------+\n",
      "|      1|     11/Introduction|\n",
      "|      2|19/Basic Engineer...|\n",
      "|      3|28/Advanced Engin...|\n",
      "|      4|  60/Hands On Course|\n",
      "|      5|     62/Case Studies|\n",
      "|      6|73/Best Practices...|\n",
      "|      7|77/130+ Data Sour...|\n",
      "|      8|82/1001 Interview...|\n",
      "|      9|87/Recommended Bo...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compoundDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1126ba0b-88fa-48d0-9ba5-79ab7f774332",
   "metadata": {},
   "source": [
    "## Counting words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e09d36e-4f0e-44ef-82ef-3f56339d5691",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_2 = Path.cwd().parent / \"Files\" / \"sections_wordcount.csv\"\n",
    "section = str(path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42d30cf9-ffcb-49d0-b36f-a276d8f5bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file into RDD\n",
    "sectionsRDD = sc.textFile(section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1274be1-2fef-447d-8c4e-fab19bafd6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,1.1,What is this Cookbook\n",
      "1,1.2,Data Engineer vs Data Scientist\n",
      "1,1.3,My Data Science Platform Blueprint\n",
      "1,1.4,Who Companies Need\n",
      "2,2.1,Learn To Code\n"
     ]
    }
   ],
   "source": [
    "# Inspect new RDD\n",
    "for row in sectionsRDD.take(5):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab1a577d-a762-430b-b9d2-a29a958fb846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split each row\n",
    "playRDD = sectionsRDD.map(lambda columns: columns.split(\",\"))\n",
    "                              #(columns[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45f8004a-c7c4-449d-ac5f-670259f6ee7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '1.1', 'What is this Cookbook']\n",
      "['1', '1.2', 'Data Engineer vs Data Scientist']\n",
      "['1', '1.3', 'My Data Science Platform Blueprint']\n",
      "['1', '1.4', 'Who Companies Need']\n",
      "['2', '2.1', 'Learn To Code']\n"
     ]
    }
   ],
   "source": [
    "# Inspect new RDD\n",
    "for row in playRDD.take(5):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60dc1b86-209c-457d-a7eb-060fc0fd5546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only take 3rd column (text)\n",
    "selecttextRDD = playRDD.map(lambda columns: columns[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04de83e1-dee2-4d77-bdff-c66f3ab41108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is this Cookbook\n",
      "Data Engineer vs Data Scientist\n",
      "My Data Science Platform Blueprint\n",
      "Who Companies Need\n",
      "Learn To Code\n"
     ]
    }
   ],
   "source": [
    "# Inspect new RDD\n",
    "for row in selecttextRDD.take(5):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c03b923f-febb-44da-a4d9-cc1cefdcb76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten RDD\n",
    "flatRDD = selecttextRDD.flatMap(lambda text: text.split(\" \")).map(lambda word: (word,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9eb0725b-0e51-4f75-ad63-53dae1f0babc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('What', 1)\n",
      "('is', 1)\n",
      "('this', 1)\n",
      "('Cookbook', 1)\n",
      "('Data', 1)\n"
     ]
    }
   ],
   "source": [
    "# Inspect new RDD\n",
    "for row in flatRDD.take(5):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2aab775-2c72-44f7-bde2-05faeb4bc4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the Words and sort by key\n",
    "reducedRDD = flatRDD.reduceByKey(lambda v1,v2: v1+v2).sortByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78c99ac1-5d8b-42bc-bc6c-ee2dd4fe0f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('(AWS)', 1)\n",
      "('(GCP)', 1)\n",
      "('A', 2)\n",
      "('API', 1)\n",
      "('About', 1)\n",
      "('Academic', 1)\n",
      "('Agile', 1)\n",
      "('Airbnb', 1)\n",
      "('Amazon', 2)\n",
      "('And', 6)\n",
      "('Apache', 3)\n",
      "('Articles', 1)\n",
      "('Azure', 1)\n",
      "('BMW', 1)\n",
      "('Baidu', 1)\n",
      "('Blackrock', 1)\n",
      "('Blog', 1)\n",
      "('Blueprint', 1)\n",
      "('Booking.com', 1)\n",
      "('Books', 2)\n"
     ]
    }
   ],
   "source": [
    "# Inspect new RDD\n",
    "for row in reducedRDD.take(20):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945a1f99-f379-47ae-9756-a933efeae0cd",
   "metadata": {},
   "source": [
    "## Turn RDD back into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "537355f0-c2d5-4af1-ae74-407f98af468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create schema for Wordcount DataFrame\n",
    "from pyspark.sql.types import *\n",
    "wordcountSchema = StructType([\n",
    "StructField(\"Word\",StringType()),\n",
    "StructField(\"Count\",IntegerType())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c0ef5c3-f0be-4bfe-a53d-30bcbed183af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       Word|Count|\n",
      "+-----------+-----+\n",
      "|      (AWS)|    1|\n",
      "|      (GCP)|    1|\n",
      "|          A|    2|\n",
      "|        API|    1|\n",
      "|      About|    1|\n",
      "|   Academic|    1|\n",
      "|      Agile|    1|\n",
      "|     Airbnb|    1|\n",
      "|     Amazon|    2|\n",
      "|        And|    6|\n",
      "|     Apache|    3|\n",
      "|   Articles|    1|\n",
      "|      Azure|    1|\n",
      "|        BMW|    1|\n",
      "|      Baidu|    1|\n",
      "|  Blackrock|    1|\n",
      "|       Blog|    1|\n",
      "|  Blueprint|    1|\n",
      "|Booking.com|    1|\n",
      "|      Books|    2|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "wordcountDF = spark.createDataFrame(reducedRDD,wordcountSchema)\n",
    "wordcountDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a5b2897-937c-4735-93ea-f2547714a5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       Word|Count|\n",
      "+-----------+-----+\n",
      "|       Data|   48|\n",
      "|    Science|   40|\n",
      "|        And|    6|\n",
      "|   Platform|    3|\n",
      "| Processing|    3|\n",
      "|     Apache|    3|\n",
      "|        and|    3|\n",
      "|       What|    2|\n",
      "|     Amazon|    2|\n",
      "|      Books|    2|\n",
      "|    Courses|    2|\n",
      "|         to|    2|\n",
      "|       Nifi|    2|\n",
      "|    Twitter|    2|\n",
      "|   Security|    2|\n",
      "|         To|    2|\n",
      "|      Learn|    2|\n",
      "|      Cloud|    2|\n",
      "|          A|    2|\n",
      "|Development|    2|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort the DataFrame after Count column\n",
    "wordcountDF.sort(wordcountDF.Count.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a3375f-383f-450f-aa72-176b4cf8e111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
